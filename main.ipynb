{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "import easydict\n",
    "from torch import Tensor, device, dtype, nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sksurv.metrics import concordance_index_ipcw, brier_score\n",
    "\n",
    "from pycox.datasets import metabric, support\n",
    "from pycox.models import LogisticHazard\n",
    "from pycox.preprocessing.feature_transforms import OrderedCategoricalLong\n",
    "from pycox.evaluation import EvalSurv\n",
    "from pycox.models.loss import NLLPCHazardLoss\n",
    "from pycox.preprocessing.discretization import (make_cuts, IdxDiscUnknownC, _values_if_series,\n",
    "    DiscretizeUnknownC, Duration2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from survtrace.dataset import load_data\n",
    "from survtrace.model import SurvTraceSingle, SurvTraceMulti\n",
    "from survtrace import Evaluator\n",
    "from survtrace import Trainer\n",
    "from survtrace import STConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "_ = torch.manual_seed(42)\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use pytorch-cuda for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\Documents\\GitHub\\DLH-SurvTrace\\survtrace\\train_utils.py:208: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\python_arg_parser.cpp:1420.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train-0]: 0.7065458351961718\n",
      "[Val-0]: 0.678919792175293\n",
      "[Train-1]: 0.6774175704801969\n",
      "[Val-1]: 0.6781501770019531\n",
      "[Train-2]: 0.6744692639999239\n",
      "[Val-2]: 0.682232141494751\n",
      "EarlyStopping counter: 1 out of 5\n",
      "[Train-3]: 0.6726086230203588\n",
      "[Val-3]: 0.67551189661026\n",
      "[Train-4]: 0.671198615153004\n",
      "[Val-4]: 0.6772618293762207\n",
      "EarlyStopping counter: 1 out of 5\n",
      "[Train-5]: 0.6698064597816882\n",
      "[Val-5]: 0.6774457693099976\n",
      "EarlyStopping counter: 2 out of 5\n",
      "[Train-6]: 0.6738634495028498\n",
      "[Val-6]: 0.6738459467887878\n",
      "[Train-7]: 0.6687021280196134\n",
      "[Val-7]: 0.6729950904846191\n",
      "[Train-8]: 0.6681776254346775\n",
      "[Val-8]: 0.6743725538253784\n",
      "EarlyStopping counter: 1 out of 5\n",
      "[Train-9]: 0.6674415661744819\n",
      "[Val-9]: 0.6742698550224304\n",
      "EarlyStopping counter: 2 out of 5\n",
      "[Train-10]: 0.6669871949918382\n",
      "[Val-10]: 0.675478994846344\n",
      "EarlyStopping counter: 3 out of 5\n",
      "[Train-11]: 0.6668515501755427\n",
      "[Val-11]: 0.6739497184753418\n",
      "EarlyStopping counter: 4 out of 5\n",
      "[Train-12]: 0.6663393539747855\n",
      "[Val-12]: 0.672863245010376\n",
      "[Train-13]: 0.6655668221491882\n",
      "[Val-13]: 0.6743597984313965\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m# execute training\u001b[39;00m\n\u001b[0;32m      9\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(model)\n\u001b[1;32m---> 10\u001b[0m trainer\u001b[39m.\u001b[39;49mfit((df_train, df_y_train), (df_val, df_y_val))\n\u001b[0;32m     12\u001b[0m \u001b[39m# evaluating\u001b[39;00m\n\u001b[0;32m     13\u001b[0m evaluator \u001b[39m=\u001b[39m Evaluator(df, df_train\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Robin\\Documents\\GitHub\\DLH-SurvTrace\\survtrace\\train_utils.py:497\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, train_set, val_set, batch_size, epochs, learning_rate, weight_decay, val_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    485\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_single_event(\n\u001b[0;32m    486\u001b[0m             train_set\u001b[39m=\u001b[39mtrain_set,\n\u001b[0;32m    487\u001b[0m             val_set\u001b[39m=\u001b[39mval_set,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    494\u001b[0m     )\n\u001b[0;32m    496\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_event \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 497\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_multi_event(\n\u001b[0;32m    498\u001b[0m             train_set\u001b[39m=\u001b[39mtrain_set,\n\u001b[0;32m    499\u001b[0m             val_set\u001b[39m=\u001b[39mval_set,\n\u001b[0;32m    500\u001b[0m             batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m    501\u001b[0m             epochs\u001b[39m=\u001b[39mepochs,\n\u001b[0;32m    502\u001b[0m             learning_rate\u001b[39m=\u001b[39mlearning_rate,\n\u001b[0;32m    503\u001b[0m             weight_decay\u001b[39m=\u001b[39mweight_decay,\n\u001b[0;32m    504\u001b[0m             val_batch_size\u001b[39m=\u001b[39mval_batch_size,\n\u001b[0;32m    505\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    506\u001b[0m     )\n\u001b[0;32m    508\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Robin\\Documents\\GitHub\\DLH-SurvTrace\\survtrace\\train_utils.py:441\u001b[0m, in \u001b[0;36mTrainer.train_multi_event\u001b[1;34m(self, train_set, val_set, batch_size, epochs, learning_rate, weight_decay, val_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[0;32m    440\u001b[0m     batch_loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m--> 441\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m    442\u001b[0m     epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m batch_loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m    444\u001b[0m train_loss_list\u001b[39m.\u001b[39mappend(epoch_loss \u001b[39m/\u001b[39m (batch_idx\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Robin\\Documents\\GitHub\\DLH-SurvTrace\\.venv\\lib\\site-packages\\torch\\optim\\optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Robin\\Documents\\GitHub\\DLH-SurvTrace\\survtrace\\train_utils.py:204\u001b[0m, in \u001b[0;36mBERTAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39m# Add grad clipping\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39mif\u001b[39;00m group[\u001b[39m'\u001b[39m\u001b[39mmax_grad_norm\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m     clip_grad_norm_(p, group[\u001b[39m'\u001b[39;49m\u001b[39mmax_grad_norm\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    206\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[39m# In-place operations to update the averages at the same time\u001b[39;00m\n\u001b[0;32m    208\u001b[0m next_m\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1, grad)\n",
      "File \u001b[1;32mc:\\Users\\Robin\\Documents\\GitHub\\DLH-SurvTrace\\.venv\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:43\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[0;32m     41\u001b[0m     total_norm \u001b[39m=\u001b[39m norms[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(norms) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mmax(torch\u001b[39m.\u001b[39mstack(norms))\n\u001b[0;32m     42\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m     total_norm \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnorm(torch\u001b[39m.\u001b[39mstack([torch\u001b[39m.\u001b[39mnorm(g\u001b[39m.\u001b[39mdetach(), norm_type)\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m grads]), norm_type)\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m error_if_nonfinite \u001b[39mand\u001b[39;00m torch\u001b[39m.\u001b[39mlogical_or(total_norm\u001b[39m.\u001b[39misnan(), total_norm\u001b[39m.\u001b[39misinf()):\n\u001b[0;32m     45\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m     46\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe total norm of order \u001b[39m\u001b[39m{\u001b[39;00mnorm_type\u001b[39m}\u001b[39;00m\u001b[39m for gradients from \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     47\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m`parameters` is non-finite, so it cannot be clipped. To disable \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     48\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mthis error and scale the gradients by the non-finite norm anyway, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     49\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mset `error_if_nonfinite=False`\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Robin\\Documents\\GitHub\\DLH-SurvTrace\\.venv\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:43\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     41\u001b[0m     total_norm \u001b[39m=\u001b[39m norms[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(norms) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m torch\u001b[39m.\u001b[39mmax(torch\u001b[39m.\u001b[39mstack(norms))\n\u001b[0;32m     42\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m     total_norm \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnorm(torch\u001b[39m.\u001b[39mstack([torch\u001b[39m.\u001b[39;49mnorm(g\u001b[39m.\u001b[39;49mdetach(), norm_type)\u001b[39m.\u001b[39mto(device) \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m grads]), norm_type)\n\u001b[0;32m     44\u001b[0m \u001b[39mif\u001b[39;00m error_if_nonfinite \u001b[39mand\u001b[39;00m torch\u001b[39m.\u001b[39mlogical_or(total_norm\u001b[39m.\u001b[39misnan(), total_norm\u001b[39m.\u001b[39misinf()):\n\u001b[0;32m     45\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m     46\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe total norm of order \u001b[39m\u001b[39m{\u001b[39;00mnorm_type\u001b[39m}\u001b[39;00m\u001b[39m for gradients from \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     47\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m`parameters` is non-finite, so it cannot be clipped. To disable \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     48\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mthis error and scale the gradients by the non-finite norm anyway, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     49\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mset `error_if_nonfinite=False`\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Robin\\Documents\\GitHub\\DLH-SurvTrace\\.venv\\lib\\site-packages\\torch\\functional.py:1485\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[0;32m   1483\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(p, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1484\u001b[0m         _dim \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(ndim)]  \u001b[39m# noqa: C416 TODO: rewrite as list(range(m))\u001b[39;00m\n\u001b[1;32m-> 1485\u001b[0m         \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mnorm(\u001b[39minput\u001b[39;49m, p, dim\u001b[39m=\u001b[39;49m_dim, keepdim\u001b[39m=\u001b[39;49mkeepdim)  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[39m# TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m \u001b[39m# remove the overloads where dim is an int and replace with BraodcastingList1\u001b[39;00m\n\u001b[0;32m   1489\u001b[0m \u001b[39m# and remove next four lines, replace _dim with dim\u001b[39;00m\n\u001b[0;32m   1490\u001b[0m \u001b[39mif\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "STConfig['data'] = 'seer'\n",
    "df, df_train, df_y_train, df_test, df_y_test, df_val, df_y_val = load_data(STConfig)\n",
    "\n",
    "# initialize model\n",
    "model = SurvTraceMulti(STConfig)\n",
    "\n",
    "# execute training\n",
    "trainer = Trainer(model)\n",
    "trainer.fit((df_train, df_y_train), (df_val, df_y_val))\n",
    "\n",
    "# evaluating\n",
    "evaluator = Evaluator(df, df_train.index)\n",
    "evaluator.eval(model, (df_test, df_y_test))\n",
    "\n",
    "print(\"done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
